{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n",
      "Pulling search term links...\n",
      "1st degree done.\n",
      "Starting second/third degree search...\n",
      "numlinks: 54612\n",
      "Graph complete.\n",
      "time pulling data: 163.946688\n",
      "time making dict: 70.612718\n",
      "Nodes: 60444 Edges: 128565\n",
      "Skipped Links: 4\n"
     ]
    }
   ],
   "source": [
    "#using imported package wikipedia and (I think) Mediawiki API\n",
    "#using Networkx to build graph\n",
    "\n",
    "%pylab inline\n",
    "import time\n",
    "import wikipedia\n",
    "import networkx as nx\n",
    "from numpy.random import choice\n",
    "\n",
    "g = nx.Graph()\n",
    "\n",
    "#Number of terms to take on first degree of separation\n",
    "N = 5\n",
    "search_term = \"Chemistry\"\n",
    "\n",
    "#Adds all new terms as nodes and connects with edge to original term\n",
    "def ModGraph(g,term,links):\n",
    "    g.add_nodes_from(links)\n",
    "    for i in links:\n",
    "        g.add_edge(term,i)\n",
    "\n",
    "\n",
    "print(\"Pulling search term links...\")\n",
    "\n",
    "#First degree from search term\n",
    "#pull links from page using API\n",
    "s = wikipedia.page(search_term)\n",
    "\n",
    "#Adding search_term node\n",
    "g.add_node(search_term)\n",
    "\n",
    "    \n",
    "ModGraph(g,search_term,s.links)\n",
    "print(\"1st degree done.\")\n",
    "\n",
    "\n",
    "time_total_data = 0\n",
    "time_total_graph = 0\n",
    "\n",
    "#selectin N random terms to follow all the way out\n",
    "randterms = [s.links[i] for i in choice(len(s.links),N)]\n",
    "\n",
    "\n",
    "print(\"Starting second/third degree search...\")\n",
    "skipcount = 0\n",
    "\n",
    "#Below for loops follow the random links out two more degrees (random term --> link --> link)\n",
    "for term in randterms:\n",
    "    try:\n",
    "        t0 = time.time()\n",
    "        s1 = wikipedia.page(term)\n",
    "        t1 = time.time()\n",
    "        t2 = time.time()\n",
    "        ModGraph(g,term,s1.links)\n",
    "        t3 = time.time()\n",
    "        time_total_graph += (t3-t2)\n",
    "        time_total_data += (t1-t0)\n",
    "        randterms1 = s1.links\n",
    "        for term1 in randterms1:\n",
    "            t0 = time.time()\n",
    "            s2 = wikipedia.page(term1)\n",
    "            t1 = time.time()\n",
    "            t2 = time.time()\n",
    "            ModGraph(g,term1,s2.links)\n",
    "            t3 = time.time()\n",
    "            time_total_graph += (t3-t2)\n",
    "            time_total_data += (t1-t0)\n",
    "        print(\"numlinks: %d\" % g.number_of_nodes())\n",
    "    except:\n",
    "        #in case of errors querying API, just count link and skip\n",
    "        skipcount += 1\n",
    "        continue\n",
    "print(\"Graph complete.\")\n",
    "\n",
    "\n",
    "print(\"time pulling data: %f\" % (time_total_data))\n",
    "print(\"time making dict: %f\" % (time_total_graph))\n",
    "print(\"Nodes: %d Edges: %d\" % (g.number_of_nodes(),g.number_of_edges()))\n",
    "print(\"Skipped Links: %d\" % skipcount)\n",
    "\n",
    "#Save graph to gml file for loading into Gephi\n",
    "nx.write_gml(g,\"%s%dfull.gml\" % (search_term,N))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
